{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "awards_players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/awards_players_cleaned.csv')\n",
    "coaches_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/coaches_cleaned.csv')\n",
    "players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_cleaned.csv')\n",
    "players_teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_teams_cleaned.csv')\n",
    "series_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/series_post_cleaned.csv')\n",
    "teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_cleaned.csv')\n",
    "teams_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_post_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain data from only 9 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_model = awards_players_cleaned[awards_players_cleaned['year'] != 10]\n",
    "coaches_model = coaches_cleaned[coaches_cleaned['year'] != 10]\n",
    "players_teams_model = players_teams_cleaned[players_teams_cleaned['year'] != 10]\n",
    "series_post_model = series_post_cleaned[series_post_cleaned['year'] != 10]\n",
    "teams_model = teams_cleaned[teams_cleaned['year'] != 10]\n",
    "teams_post_model = teams_post_cleaned[teams_post_cleaned['year'] != 10]\n",
    "\n",
    "os.makedirs('../data/basketballPlayoffs_model', exist_ok=True)\n",
    "\n",
    "awards_players_model.to_csv('../data/basketballPlayoffs_model/awards_players_model.csv', index=False)\n",
    "coaches_model.to_csv('../data/basketballPlayoffs_model/coaches_model.csv', index=False)\n",
    "players_cleaned.to_csv('../data/basketballPlayoffs_model/players_model.csv', index=False)\n",
    "players_teams_model.to_csv('../data/basketballPlayoffs_model/players_teams_model.csv', index=False)\n",
    "series_post_model.to_csv('../data/basketballPlayoffs_model/series_post_model.csv', index=False)\n",
    "teams_model.to_csv('../data/basketballPlayoffs_model/teams_model.csv', index=False)\n",
    "teams_post_model.to_csv('../data/basketballPlayoffs_model/teams_post_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overalls from only 9 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_overall_avg = players_teams_model.groupby('playerID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "players_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "players_overall_avg['OVERALL_ALL_TIME'] = players_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "players_overall_avg.to_csv('../data/basketballPlayoffs_model/players_overall_all_time_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_players = players_teams_model[players_teams_model['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_avg = rookie_players['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_avg_df = pd.DataFrame({'rookie_overall_avg': [rookie_overall_avg]})\n",
    "\n",
    "rookie_overall_avg_df.to_csv('../data/basketballPlayoffs_model/rookie_overall_avg_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_coaches = coaches_model[coaches_model['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_coaches_avg = rookie_coaches['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_coaches_avg_df = pd.DataFrame({'rookie_overall_coaches_avg': [rookie_overall_coaches_avg]})\n",
    "\n",
    "rookie_overall_coaches_avg_df.to_csv('../data/basketballPlayoffs_model/rookie_overall_coaches_avg_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_overall_avg = coaches_model.groupby('coachID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "coaches_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "coaches_overall_avg['OVERALL_ALL_TIME'] = coaches_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "coaches_overall_avg.to_csv('../data/basketballPlayoffs_model/coaches_overall_all_time_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain ranks from the 10th year to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoffs_10th_year = teams_cleaned[teams_cleaned['year'] == 10][['tmID', 'playoff']]\n",
    "\n",
    "playoffs_10th_year.to_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain teams line up and coach from the 10th year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_model_10th_year = coaches_cleaned[coaches_cleaned['year'] == 10][['coachID', 'tmID',]]\n",
    "\n",
    "coaches_model_10th_year.to_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_model_10th_year = players_teams_cleaned[players_teams_cleaned['year'] == 10][['playerID','tmID']]\n",
    "\n",
    "players_model_10th_year = players_model_10th_year.sort_values(by='tmID')\n",
    "\n",
    "players_model_10th_year.to_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add overalls calculated from 9 years to the 10th year players and coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv')\n",
    "players_overall_all_time_model = pd.read_csv('../data/basketballPlayoffs_model/players_overall_all_time_model.csv')\n",
    "\n",
    "rookie_avg = 5.6 \n",
    "\n",
    "players_model_10th_year = players_model_10th_year.merge(\n",
    "    players_overall_all_time_model[['playerID', 'OVERALL_ALL_TIME']],\n",
    "    on='playerID',\n",
    "    how='left'\n",
    ").fillna({'OVERALL_ALL_TIME': rookie_avg})\n",
    "\n",
    "players_model_10th_year.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "players_model_10th_year.to_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv')\n",
    "coaches_overall_all_time_model = pd.read_csv('../data/basketballPlayoffs_model/coaches_overall_all_time_model.csv')\n",
    "\n",
    "rookie_avg_coach = 8.9 \n",
    "\n",
    "coaches_model_10th_year = coaches_model_10th_year.merge(\n",
    "    coaches_overall_all_time_model[['coachID', 'OVERALL_ALL_TIME']],\n",
    "    on='coachID',\n",
    "    how='left'\n",
    ").fillna({'OVERALL_ALL_TIME': rookie_avg_coach})\n",
    "\n",
    "coaches_model_10th_year.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "coaches_model_10th_year.to_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the teams players composition and their respective overalls calculate the team overall (mean of all players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv')\n",
    "\n",
    "team_overall = players_model_10th_year.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall['overall_team'] = team_overall['OVERALL'].round(1)\n",
    "\n",
    "team_overall = team_overall.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall.to_csv('../data/basketballPlayoffs_model/team_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the team coaches and their respective overalls calculate the coach overall (mean of all coaches(1 or more than 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv')\n",
    "\n",
    "team_overall_coaches = coaches_model_10th_year.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall_coaches['overall_team_coach'] = team_overall_coaches['OVERALL'].round(1)\n",
    "\n",
    "team_overall_coaches = team_overall_coaches.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall_coaches.to_csv('../data/basketballPlayoffs_model/team_overall_coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create team final overall ( 70% team + 30% coach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_overall = pd.read_csv('../data/basketballPlayoffs_model/team_overall.csv')\n",
    "team_overall_coach = pd.read_csv('../data/basketballPlayoffs_model/team_overall_coaches.csv')\n",
    "teams_model = pd.read_csv('../data/basketballPlayoffs_model/teams_model.csv')\n",
    "\n",
    "merged_df = pd.merge(team_overall, team_overall_coach, on='tmID')\n",
    "\n",
    "merged_df['overall_team_final'] = (merged_df['overall_team'] * 0.9) + (merged_df['overall_team_coach'] * 0.1)\n",
    "merged_df['overall_team_final'] = merged_df['overall_team_final'].round(2)\n",
    "\n",
    "merged_df = pd.merge(merged_df, teams_model[['tmID', 'confID']], on='tmID', how='left')\n",
    "\n",
    "final_df = merged_df[['tmID', 'confID', 'overall_team_final']]\n",
    "\n",
    "final_df = final_df.drop_duplicates(subset='tmID')\n",
    "\n",
    "final_df = final_df.sort_values(by='overall_team_final', ascending=True)\n",
    "\n",
    "final_df.to_csv('../data/basketballPlayoffs_model/team_final_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams that go to the playoffs acording to the previsions:\n",
      "\n",
      "    tmID  confID  overall_team_final\n",
      "12     8       1              11.170\n",
      "11    16       1               9.130\n",
      "10     5       0               8.950\n",
      "9     13       1               8.680\n",
      "8     17       1               8.540\n",
      "5     11       0               8.280\n",
      "4      7       0               8.210\n",
      "3     19       0               8.180\n",
      "\n",
      "Teams that are in the playoffs and in the previsions:\n",
      "\n",
      "   tmID  confID  overall_team_final  playoff\n",
      "0     8       1              11.170        1\n",
      "1    16       1               9.130        1\n",
      "2     5       0               8.950        1\n",
      "3    13       1               8.680        1\n",
      "4    17       1               8.540        1\n",
      "6     7       0               8.210        1\n",
      "7    19       0               8.180        1\n",
      "\n",
      "The accuracy is 87.50%\n"
     ]
    }
   ],
   "source": [
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "top_teams_by_conf = team_final_overall.sort_values(by='overall_team_final', ascending=False).groupby('confID').head(4)\n",
    "\n",
    "print(\"Teams that go to the playoffs acording to the previsions:\\n\")\n",
    "print(top_teams_by_conf)\n",
    "\n",
    "comparison = top_teams_by_conf.merge(playoffs_10th_year, on='tmID', how='left')\n",
    "\n",
    "correct_predictions = comparison[comparison['playoff'] == 1]\n",
    "\n",
    "print(\"\\nTeams that are in the playoffs and in the previsions:\\n\")\n",
    "print(correct_predictions)\n",
    "\n",
    "accuracy = len(correct_predictions) / len(top_teams_by_conf) * 100\n",
    "print(f\"\\nThe accuracy is {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Playoff Predictions Summary:\n",
      "================================================================================\n",
      " Team_ID  Probability  Adjusted_Prob  Predicted  Actual\n",
      "   11       0.625         0.631          1         1   \n",
      "    7       0.625         0.631          1         1   \n",
      "    8       0.625         0.631          1         1   \n",
      "    5       0.625         0.631          1         1   \n",
      "   19       0.625         0.631          1         1   \n",
      "    4       0.624         0.630          1         0   \n",
      "    0       0.623         0.629          1         0   \n",
      "    2       0.623         0.629          1         1   \n",
      "   16       0.603         0.608          0         1   \n",
      "   13       0.586         0.592          0         0   \n",
      "   17       0.582         0.588          0         1   \n",
      "   10       0.580         0.586          0         0   \n",
      "   15       0.579         0.585          0         0   \n",
      "\n",
      "================================================================================\n",
      "Total Error: 6.04\n",
      "Accuracy: 69.2%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set pandas display options for better table formatting\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "# Load the data with tmID as integer\n",
    "team_data = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv', dtype={'tmID': int})\n",
    "playoff_data = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv', dtype={'tmID': int})\n",
    "\n",
    "# Prepare features and target for training\n",
    "X = team_data[['overall_team_final', 'confID']].values\n",
    "y = playoff_data['playoff'].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train SVM model with probability estimates\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_scaled, y)\n",
    "\n",
    "# Get probability predictions\n",
    "probabilities = svm_model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# Adjust probabilities to sum to 8\n",
    "adjusted_probabilities = 8 * probabilities / np.sum(probabilities)\n",
    "\n",
    "# Create predicted column (1 for top 8 probabilities, 0 for others)\n",
    "predicted = np.zeros(len(adjusted_probabilities))\n",
    "top_8_indices = np.argsort(adjusted_probabilities)[-8:]\n",
    "predicted[top_8_indices] = 1\n",
    "\n",
    "# Create and format final predictions DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Team_ID': team_data['tmID'],\n",
    "    'Probability': probabilities,\n",
    "    'Adjusted_Prob': adjusted_probabilities,\n",
    "    'Predicted': predicted.astype(int),\n",
    "    'Actual': playoff_data['playoff']\n",
    "})\n",
    "\n",
    "# Sort by adjusted probability\n",
    "predictions_df = predictions_df.sort_values('Adjusted_Prob', ascending=False)\n",
    "\n",
    "# Calculate error and accuracy\n",
    "error = np.sum(np.abs(predictions_df['Adjusted_Prob'] - predictions_df['Actual']))\n",
    "correct_predictions = sum(predictions_df['Predicted'] == predictions_df['Actual'])\n",
    "accuracy_pct = (correct_predictions / len(predictions_df)) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPlayoff Predictions Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(predictions_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Total Error: {error:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_pct:.1f}%\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('../data/basketballPlayoffs_model/playoff_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0      2          0       7.900       1         1  \n",
      "1      0          0       7.970       0         0  \n",
      "2      4          0       8.060       0         0  \n",
      "3     19          0       8.180       1         1  \n",
      "4      7          0       8.210       1         1  \n",
      "5     11          0       8.280       0         1  \n",
      "6     15          1       8.380       1         0  \n",
      "7     10          1       8.450       0         0  \n",
      "8     17          1       8.540       1         1  \n",
      "9     13          1       8.680       0         0  \n",
      "10     5          0       8.950       1         1  \n",
      "11    16          1       9.130       1         1  \n",
      "12     8          1      11.170       1         1  \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "\n",
      "KNN Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_knn(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Adjust k_values based on number of samples\n",
    "    n_samples = len(X)\n",
    "    k_values = [k for k in [3, 5] if k < n_samples]  # Only use k values less than n_samples\n",
    "    if not k_values:  # If no valid k values, use k=1\n",
    "        k_values = [1]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "        knn.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, knn.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = knn\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "knn_conf_0, scaler_conf_0 = train_conference_knn(conf_0_data, conf_0_playoffs)\n",
    "knn_conf_1, scaler_conf_1 = train_conference_knn(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, knn_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = knn_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, knn_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, knn_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nKNN Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC (Random Forest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0      2          0       7.900       1         1  \n",
      "1      0          0       7.970       0         0  \n",
      "2      4          0       8.060       0         0  \n",
      "3     19          0       8.180       1         1  \n",
      "4      7          0       8.210       1         1  \n",
      "5     11          0       8.280       0         1  \n",
      "6     15          1       8.380       1         0  \n",
      "7     10          1       8.450       0         0  \n",
      "8     17          1       8.540       1         1  \n",
      "9     13          1       8.680       0         0  \n",
      "10     5          0       8.950       1         1  \n",
      "11    16          1       9.130       1         1  \n",
      "12     8          1      11.170       1         1  \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_rf(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different Random Forest configurations\n",
    "    rf_configs = {\n",
    "        'default': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'balanced': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "        'more_trees': RandomForestClassifier(n_estimators=200, min_samples_split=2, random_state=42)\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, rf in rf_configs.items():\n",
    "        rf.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, rf.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = rf\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "rf_conf_0, scaler_conf_0 = train_conference_rf(conf_0_data, conf_0_playoffs)\n",
    "rf_conf_1, scaler_conf_1 = train_conference_rf(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, rf_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = rf_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, rf_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, rf_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nRandom Forest Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0      2          0       7.900       1         1  \n",
      "1      0          0       7.970       1         0  \n",
      "2      4          0       8.060       1         0  \n",
      "3     19          0       8.180       1         1  \n",
      "4      7          0       8.210       0         1  \n",
      "5     11          0       8.280       0         1  \n",
      "6     15          1       8.380       1         0  \n",
      "7     10          1       8.450       1         0  \n",
      "8     17          1       8.540       1         1  \n",
      "9     13          1       8.680       1         0  \n",
      "10     5          0       8.950       0         1  \n",
      "11    16          1       9.130       0         1  \n",
      "12     8          1      11.170       0         1  \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.38      0.38         8\n",
      "\n",
      "    accuracy                           0.23        13\n",
      "   macro avg       0.19      0.19      0.19        13\n",
      "weighted avg       0.23      0.23      0.23        13\n",
      "\n",
      "\n",
      "Logistic Regression Accuracy: 23.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_lr(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different Logistic Regression configurations\n",
    "    lr_configs = {\n",
    "        'default': LogisticRegression(random_state=42),\n",
    "        'balanced': LogisticRegression(class_weight='balanced', random_state=42),\n",
    "        'stronger_reg': LogisticRegression(C=0.1, random_state=42)\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, lr in lr_configs.items():\n",
    "        lr.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, lr.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = lr\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "lr_conf_0, scaler_conf_0 = train_conference_lr(conf_0_data, conf_0_playoffs)\n",
    "lr_conf_1, scaler_conf_1 = train_conference_lr(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, lr_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = lr_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, lr_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, lr_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nLogistic Regression Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0      2          0       7.900       1         1  \n",
      "1      0          0       7.970       0         0  \n",
      "2      4          0       8.060       0         0  \n",
      "3     19          0       8.180       1         1  \n",
      "4      7          0       8.210       1         1  \n",
      "5     11          0       8.280       0         1  \n",
      "6     15          1       8.380       1         0  \n",
      "7     10          1       8.450       0         0  \n",
      "8     17          1       8.540       1         1  \n",
      "9     13          1       8.680       0         0  \n",
      "10     5          0       8.950       1         1  \n",
      "11    16          1       9.130       1         1  \n",
      "12     8          1      11.170       1         1  \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "\n",
      "Decision Tree Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_dt(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different Decision Tree configurations\n",
    "    dt_configs = {\n",
    "        'default': DecisionTreeClassifier(random_state=42),\n",
    "        'balanced': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        'min_samples': DecisionTreeClassifier(min_samples_split=3, random_state=42)\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, dt in dt_configs.items():\n",
    "        dt.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, dt.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = dt\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "dt_conf_0, scaler_conf_0 = train_conference_dt(conf_0_data, conf_0_playoffs)\n",
    "dt_conf_1, scaler_conf_1 = train_conference_dt(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, dt_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = dt_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, dt_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, dt_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nDecision Tree Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
