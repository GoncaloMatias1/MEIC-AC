{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "awards_players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/awards_players_cleaned.csv')\n",
    "coaches_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/coaches_cleaned.csv')\n",
    "players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_cleaned.csv')\n",
    "players_teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_teams_cleaned.csv')\n",
    "series_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/series_post_cleaned.csv')\n",
    "teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_cleaned.csv')\n",
    "teams_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_post_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain data from only 9 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_model = awards_players_cleaned[awards_players_cleaned['year'] != 10]\n",
    "coaches_model = coaches_cleaned[coaches_cleaned['year'] != 10]\n",
    "players_teams_model = players_teams_cleaned[players_teams_cleaned['year'] != 10]\n",
    "series_post_model = series_post_cleaned[series_post_cleaned['year'] != 10]\n",
    "teams_model = teams_cleaned[teams_cleaned['year'] != 10]\n",
    "teams_post_model = teams_post_cleaned[teams_post_cleaned['year'] != 10]\n",
    "\n",
    "os.makedirs('../data/basketballPlayoffs_model', exist_ok=True)\n",
    "\n",
    "awards_players_model.to_csv('../data/basketballPlayoffs_model/awards_players_model.csv', index=False)\n",
    "coaches_model.to_csv('../data/basketballPlayoffs_model/coaches_model.csv', index=False)\n",
    "players_cleaned.to_csv('../data/basketballPlayoffs_model/players_model.csv', index=False)\n",
    "players_teams_model.to_csv('../data/basketballPlayoffs_model/players_teams_model.csv', index=False)\n",
    "series_post_model.to_csv('../data/basketballPlayoffs_model/series_post_model.csv', index=False)\n",
    "teams_model.to_csv('../data/basketballPlayoffs_model/teams_model.csv', index=False)\n",
    "teams_post_model.to_csv('../data/basketballPlayoffs_model/teams_post_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overalls from only 9 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_overall_avg = players_teams_model.groupby('playerID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "players_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "players_overall_avg['OVERALL_ALL_TIME'] = players_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "players_overall_avg.to_csv('../data/basketballPlayoffs_model/players_overall_all_time_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_players = players_teams_model[players_teams_model['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_avg = rookie_players['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_avg_df = pd.DataFrame({'rookie_overall_avg': [rookie_overall_avg]})\n",
    "\n",
    "rookie_overall_avg_df.to_csv('../data/basketballPlayoffs_model/rookie_overall_avg_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_coaches = coaches_model[coaches_model['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_coaches_avg = rookie_coaches['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_coaches_avg_df = pd.DataFrame({'rookie_overall_coaches_avg': [rookie_overall_coaches_avg]})\n",
    "\n",
    "rookie_overall_coaches_avg_df.to_csv('../data/basketballPlayoffs_model/rookie_overall_coaches_avg_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_overall_avg = coaches_model.groupby('coachID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "coaches_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "coaches_overall_avg['OVERALL_ALL_TIME'] = coaches_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "coaches_overall_avg.to_csv('../data/basketballPlayoffs_model/coaches_overall_all_time_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain ranks from the 10th year to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoffs_10th_year = teams_cleaned[teams_cleaned['year'] == 10][['tmID', 'playoff']]\n",
    "\n",
    "playoffs_10th_year.to_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain teams line up and coach from the 10th year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_model_10th_year = coaches_cleaned[coaches_cleaned['year'] == 10][['coachID', 'tmID',]]\n",
    "\n",
    "coaches_model_10th_year.to_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_model_10th_year = players_teams_cleaned[players_teams_cleaned['year'] == 10][['playerID','tmID']]\n",
    "\n",
    "players_model_10th_year = players_model_10th_year.sort_values(by='tmID')\n",
    "\n",
    "players_model_10th_year.to_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add overalls calculated from 9 years to the 10th year players and coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv')\n",
    "players_overall_all_time_model = pd.read_csv('../data/basketballPlayoffs_model/players_overall_all_time_model.csv')\n",
    "\n",
    "rookie_avg = 5.6 \n",
    "\n",
    "players_model_10th_year = players_model_10th_year.merge(\n",
    "    players_overall_all_time_model[['playerID', 'OVERALL_ALL_TIME']],\n",
    "    on='playerID',\n",
    "    how='left'\n",
    ").fillna({'OVERALL_ALL_TIME': rookie_avg})\n",
    "\n",
    "players_model_10th_year.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "players_model_10th_year.to_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv')\n",
    "coaches_overall_all_time_model = pd.read_csv('../data/basketballPlayoffs_model/coaches_overall_all_time_model.csv')\n",
    "\n",
    "rookie_avg_coach = 8.9 \n",
    "\n",
    "coaches_model_10th_year = coaches_model_10th_year.merge(\n",
    "    coaches_overall_all_time_model[['coachID', 'OVERALL_ALL_TIME']],\n",
    "    on='coachID',\n",
    "    how='left'\n",
    ").fillna({'OVERALL_ALL_TIME': rookie_avg_coach})\n",
    "\n",
    "coaches_model_10th_year.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "coaches_model_10th_year.to_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the teams players composition and their respective overalls calculate the team overall (mean of all players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/players_model_10th_year.csv')\n",
    "\n",
    "team_overall = players_model_10th_year.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall['overall_team'] = team_overall['OVERALL'].round(1)\n",
    "\n",
    "team_overall = team_overall.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall.to_csv('../data/basketballPlayoffs_model/team_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given the team coaches and their respective overalls calculate the coach overall (mean of all coaches(1 or more than 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_model_10th_year = pd.read_csv('../data/basketballPlayoffs_model/coaches_model_10th_year.csv')\n",
    "\n",
    "team_overall_coaches = coaches_model_10th_year.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall_coaches['overall_team_coach'] = team_overall_coaches['OVERALL'].round(1)\n",
    "\n",
    "team_overall_coaches = team_overall_coaches.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall_coaches.to_csv('../data/basketballPlayoffs_model/team_overall_coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create team final overall ( 70% team + 30% coach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_overall = pd.read_csv('../data/basketballPlayoffs_model/team_overall.csv')\n",
    "team_overall_coach = pd.read_csv('../data/basketballPlayoffs_model/team_overall_coaches.csv')\n",
    "teams_model = pd.read_csv('../data/basketballPlayoffs_model/teams_model.csv')\n",
    "\n",
    "merged_df = pd.merge(team_overall, team_overall_coach, on='tmID')\n",
    "\n",
    "merged_df['overall_team_final'] = (merged_df['overall_team'] * 0.9) + (merged_df['overall_team_coach'] * 0.1)\n",
    "merged_df['overall_team_final'] = merged_df['overall_team_final'].round(2)\n",
    "\n",
    "merged_df = pd.merge(merged_df, teams_model[['tmID', 'confID']], on='tmID', how='left')\n",
    "\n",
    "final_df = merged_df[['tmID', 'confID', 'overall_team_final']]\n",
    "\n",
    "final_df = final_df.drop_duplicates(subset='tmID')\n",
    "\n",
    "final_df = final_df.sort_values(by='overall_team_final', ascending=True)\n",
    "\n",
    "final_df.to_csv('../data/basketballPlayoffs_model/team_final_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teams that go to the playoffs acording to the previsions:\n",
      "\n",
      "    tmID  confID  overall_team_final\n",
      "12     8       1               11.17\n",
      "11    16       1                9.13\n",
      "10     5       0                8.95\n",
      "9     13       1                8.68\n",
      "8     17       1                8.54\n",
      "5     11       0                8.28\n",
      "4      7       0                8.21\n",
      "3     19       0                8.18\n",
      "\n",
      "Teams that are in the playoffs and in the previsions:\n",
      "\n",
      "   tmID  confID  overall_team_final  playoff\n",
      "0     8       1               11.17        1\n",
      "1    16       1                9.13        1\n",
      "2     5       0                8.95        1\n",
      "3    13       1                8.68        1\n",
      "4    17       1                8.54        1\n",
      "6     7       0                8.21        1\n",
      "7    19       0                8.18        1\n",
      "\n",
      "The accuracy is 87.50%\n"
     ]
    }
   ],
   "source": [
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "top_teams_by_conf = team_final_overall.sort_values(by='overall_team_final', ascending=False).groupby('confID').head(4)\n",
    "\n",
    "print(\"Teams that go to the playoffs acording to the previsions:\\n\")\n",
    "print(top_teams_by_conf)\n",
    "\n",
    "comparison = top_teams_by_conf.merge(playoffs_10th_year, on='tmID', how='left')\n",
    "\n",
    "correct_predictions = comparison[comparison['playoff'] == 1]\n",
    "\n",
    "print(\"\\nTeams that are in the playoffs and in the previsions:\\n\")\n",
    "print(correct_predictions)\n",
    "\n",
    "accuracy = len(correct_predictions) / len(top_teams_by_conf) * 100\n",
    "print(f\"\\nThe accuracy is {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0         2           0     7.90          1       1\n",
      "1         0           0     7.97          0       0\n",
      "2         4           0     8.06          0       0\n",
      "3        19           0     8.18          0       1\n",
      "4         7           0     8.21          1       1\n",
      "5        11           0     8.28          1       1\n",
      "6        15           1     8.38          1       0\n",
      "7        10           1     8.45          0       0\n",
      "8        17           1     8.54          0       1\n",
      "9        13           1     8.68          1       0\n",
      "10        5           0     8.95          1       1\n",
      "11       16           1     9.13          1       1\n",
      "12        8           1    11.17          1       1\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60         5\n",
      "           1       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.68      0.68      0.68        13\n",
      "weighted avg       0.69      0.69      0.69        13\n",
      "\n",
      "\n",
      "SVM Accuracy: 69.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_svm(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different SVM configurations\n",
    "    svms = {\n",
    "        'default': SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced'),\n",
    "        'linear': SVC(kernel='linear', C=0.1, class_weight='balanced'),\n",
    "        'custom_rbf': SVC(kernel='rbf', C=0.5, gamma=0.1, class_weight={0: 1, 1: 2})\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, svm in svms.items():\n",
    "        svm.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, svm.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = svm\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "svm_conf_0, scaler_conf_0 = train_conference_svm(conf_0_data, conf_0_playoffs)\n",
    "svm_conf_1, scaler_conf_1 = train_conference_svm(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, svm_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    if hasattr(svm_model, 'decision_function'):\n",
    "        decision_scores = svm_model.decision_function(X_scaled)\n",
    "    else:\n",
    "        decision_scores = svm_model.predict(X_scaled)\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(decision_scores)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, svm_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, svm_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nSVM Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0         2           0     7.90          1       1\n",
      "1         0           0     7.97          0       0\n",
      "2         4           0     8.06          0       0\n",
      "3        19           0     8.18          1       1\n",
      "4         7           0     8.21          1       1\n",
      "5        11           0     8.28          0       1\n",
      "6        15           1     8.38          1       0\n",
      "7        10           1     8.45          0       0\n",
      "8        17           1     8.54          1       1\n",
      "9        13           1     8.68          0       0\n",
      "10        5           0     8.95          1       1\n",
      "11       16           1     9.13          1       1\n",
      "12        8           1    11.17          1       1\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "\n",
      "KNN Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_knn(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Adjust k_values based on number of samples\n",
    "    n_samples = len(X)\n",
    "    k_values = [k for k in [3, 5] if k < n_samples]  # Only use k values less than n_samples\n",
    "    if not k_values:  # If no valid k values, use k=1\n",
    "        k_values = [1]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "        knn.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, knn.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = knn\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "knn_conf_0, scaler_conf_0 = train_conference_knn(conf_0_data, conf_0_playoffs)\n",
    "knn_conf_1, scaler_conf_1 = train_conference_knn(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, knn_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = knn_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, knn_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, knn_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nKNN Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC (Random Forest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0         2           0     7.90          1       1\n",
      "1         0           0     7.97          0       0\n",
      "2         4           0     8.06          0       0\n",
      "3        19           0     8.18          1       1\n",
      "4         7           0     8.21          1       1\n",
      "5        11           0     8.28          0       1\n",
      "6        15           1     8.38          1       0\n",
      "7        10           1     8.45          0       0\n",
      "8        17           1     8.54          1       1\n",
      "9        13           1     8.68          0       0\n",
      "10        5           0     8.95          1       1\n",
      "11       16           1     9.13          1       1\n",
      "12        8           1    11.17          1       1\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_rf(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different Random Forest configurations\n",
    "    rf_configs = {\n",
    "        'default': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'balanced': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "        'more_trees': RandomForestClassifier(n_estimators=200, min_samples_split=2, random_state=42)\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, rf in rf_configs.items():\n",
    "        rf.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, rf.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = rf\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "rf_conf_0, scaler_conf_0 = train_conference_rf(conf_0_data, conf_0_playoffs)\n",
    "rf_conf_1, scaler_conf_1 = train_conference_rf(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, rf_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = rf_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, rf_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, rf_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nRandom Forest Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0         2           0     7.90          1       1\n",
      "1         0           0     7.97          1       0\n",
      "2         4           0     8.06          1       0\n",
      "3        19           0     8.18          1       1\n",
      "4         7           0     8.21          0       1\n",
      "5        11           0     8.28          0       1\n",
      "6        15           1     8.38          1       0\n",
      "7        10           1     8.45          1       0\n",
      "8        17           1     8.54          1       1\n",
      "9        13           1     8.68          1       0\n",
      "10        5           0     8.95          0       1\n",
      "11       16           1     9.13          0       1\n",
      "12        8           1    11.17          0       1\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.38      0.38         8\n",
      "\n",
      "    accuracy                           0.23        13\n",
      "   macro avg       0.19      0.19      0.19        13\n",
      "weighted avg       0.23      0.23      0.23        13\n",
      "\n",
      "\n",
      "Logistic Regression Accuracy: 23.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_lr(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different Logistic Regression configurations\n",
    "    lr_configs = {\n",
    "        'default': LogisticRegression(random_state=42),\n",
    "        'balanced': LogisticRegression(class_weight='balanced', random_state=42),\n",
    "        'stronger_reg': LogisticRegression(C=0.1, random_state=42)\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, lr in lr_configs.items():\n",
    "        lr.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, lr.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = lr\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "lr_conf_0, scaler_conf_0 = train_conference_lr(conf_0_data, conf_0_playoffs)\n",
    "lr_conf_1, scaler_conf_1 = train_conference_lr(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, lr_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = lr_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, lr_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, lr_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nLogistic Regression Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions vs Actual Results:\n",
      "    Team_ID  Conference  Overall  Predicted  Actual\n",
      "0         2           0     7.90          1       1\n",
      "1         0           0     7.97          0       0\n",
      "2         4           0     8.06          0       0\n",
      "3        19           0     8.18          1       1\n",
      "4         7           0     8.21          1       1\n",
      "5        11           0     8.28          0       1\n",
      "6        15           1     8.38          1       0\n",
      "7        10           1     8.45          0       0\n",
      "8        17           1     8.54          1       1\n",
      "9        13           1     8.68          0       0\n",
      "10        5           0     8.95          1       1\n",
      "11       16           1     9.13          1       1\n",
      "12        8           1    11.17          1       1\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "\n",
      "Decision Tree Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "team_final_overall = pd.read_csv('../data/basketballPlayoffs_model/team_final_overall.csv')\n",
    "playoffs_10th_year = pd.read_csv('../data/basketballPlayoffs_model/playoffs_10th_year.csv')\n",
    "\n",
    "# Create separate models for each conference\n",
    "def train_conference_dt(conf_data, conf_playoffs):\n",
    "    X = conf_data[['overall_team_final']].values\n",
    "    y = conf_playoffs['playoff'].values\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Try different Decision Tree configurations\n",
    "    dt_configs = {\n",
    "        'default': DecisionTreeClassifier(random_state=42),\n",
    "        'balanced': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "        'min_samples': DecisionTreeClassifier(min_samples_split=3, random_state=42)\n",
    "    }\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    \n",
    "    # Select the best performing model\n",
    "    for name, dt in dt_configs.items():\n",
    "        dt.fit(X_scaled, y)\n",
    "        accuracy = accuracy_score(y, dt.predict(X_scaled))\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = dt\n",
    "            best_scaler = scaler\n",
    "            \n",
    "    return best_model, best_scaler\n",
    "\n",
    "# Split data by conference\n",
    "conf_0_data = team_final_overall[team_final_overall['confID'] == 0].copy()\n",
    "conf_1_data = team_final_overall[team_final_overall['confID'] == 1].copy()\n",
    "\n",
    "# Sort by overall_team_final to ensure we're considering ranking\n",
    "conf_0_data = conf_0_data.sort_values('overall_team_final', ascending=False)\n",
    "conf_1_data = conf_1_data.sort_values('overall_team_final', ascending=False)\n",
    "\n",
    "conf_0_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_0_data['tmID'])].copy()\n",
    "conf_1_playoffs = playoffs_10th_year[playoffs_10th_year['tmID'].isin(conf_1_data['tmID'])].copy()\n",
    "\n",
    "# Train separate models for each conference\n",
    "dt_conf_0, scaler_conf_0 = train_conference_dt(conf_0_data, conf_0_playoffs)\n",
    "dt_conf_1, scaler_conf_1 = train_conference_dt(conf_1_data, conf_1_playoffs)\n",
    "\n",
    "# Make predictions with probability threshold\n",
    "def predict_playoffs(team_data, dt_model, scaler):\n",
    "    X = team_data[['overall_team_final']].values\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Get the top 4 teams based on overall_team_final\n",
    "    n_teams = len(team_data)\n",
    "    n_playoff_spots = 4\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = dt_model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Create predictions based on top 4 scores\n",
    "    predictions = np.zeros(n_teams, dtype=int)\n",
    "    top_indices = np.argsort(probabilities)[-n_playoff_spots:]\n",
    "    predictions[top_indices] = 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get predictions for each conference\n",
    "pred_conf_0 = predict_playoffs(conf_0_data, dt_conf_0, scaler_conf_0)\n",
    "pred_conf_1 = predict_playoffs(conf_1_data, dt_conf_1, scaler_conf_1)\n",
    "\n",
    "# Combine predictions\n",
    "predictions = []\n",
    "conf_0_idx = 0\n",
    "conf_1_idx = 0\n",
    "\n",
    "for idx, row in team_final_overall.iterrows():\n",
    "    if row['confID'] == 0:\n",
    "        predictions.append(pred_conf_0[conf_0_idx])\n",
    "        conf_0_idx += 1\n",
    "    else:\n",
    "        predictions.append(pred_conf_1[conf_1_idx])\n",
    "        conf_1_idx += 1\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame({\n",
    "    'Team_ID': team_final_overall['tmID'],\n",
    "    'Conference': team_final_overall['confID'],\n",
    "    'Overall': team_final_overall['overall_team_final'],\n",
    "    'Predicted': predictions,\n",
    "    'Actual': playoffs_10th_year['playoff']\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions vs Actual Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Calculate and print all metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(playoffs_10th_year['playoff'], predictions))\n",
    "\n",
    "accuracy = accuracy_score(playoffs_10th_year['playoff'], predictions) * 100\n",
    "print(f\"\\nDecision Tree Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
