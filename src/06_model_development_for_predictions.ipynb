{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VI - Model Development for 11th Year**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.1 Import Libraries and Load Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing all the necessary files to be used in the models predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "coaches_11th = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "players_teams_11th = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "teams_11th = pd.read_csv('../data/Season_11/teams.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.2 Cleaning Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We eliminated unnecessary columns for the new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coaches_11th = coaches_11th.drop(columns=['stint', 'lgID', 'year'])\n",
    "# players_teams_11th = players_teams_11th.drop(columns=['stint', 'lgID', 'year'])\n",
    "# teams_11th = teams_11th.drop(columns=['lgID', 'franchID', 'year', 'name', 'arena'])\n",
    "\n",
    "# coaches_11th.to_csv('../data/Season_11/coaches.csv', index=False)\n",
    "# players_teams_11th.to_csv('../data/Season_11/players_teams.csv', index=False)\n",
    "# teams_11th.to_csv('../data/Season_11/teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.3 Mapping Categorical Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mapped values such as teams and conferences for a better and faster evaluation of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_teams = {\n",
    "#     'ATL': 0, 'CHI': 2, 'CON': 4, 'IND': 7, \n",
    "#     'LAS': 8, 'MIN': 10, 'NYL': 11, 'PHO': 13, \n",
    "#     'SAS': 16, 'SEA': 17, 'WAS': 19, 'TUL': 20\n",
    "# }\n",
    "\n",
    "# map_conf = {\n",
    "#   'EA': 0, 'WE': 1\n",
    "# }\n",
    "\n",
    "# coaches_11th['tmID'] = coaches_11th['tmID'].map(map_teams)\n",
    "# players_teams_11th['tmID'] = players_teams_11th['tmID'].map(map_teams)\n",
    "# teams_11th['tmID'] = teams_11th['tmID'].map(map_teams)\n",
    "# teams_11th['confID'] = teams_11th['confID'].map(map_conf)\n",
    "\n",
    "# coaches_11th.to_csv('../data/Season_11/coaches.csv', index=False)\n",
    "# players_teams_11th.to_csv('../data/Season_11/players_teams.csv', index=False)\n",
    "# teams_11th.to_csv('../data/Season_11/teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.4 Import data from the past 10 years**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported previously cleaned data containing data from the past 10 seasons and also verified that there was no data beyond 10 years to avoid future errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/awards_players_cleaned.csv')\n",
    "coaches_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/coaches_cleaned.csv')\n",
    "players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_cleaned.csv')\n",
    "players_teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_teams_cleaned.csv')\n",
    "series_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/series_post_cleaned.csv')\n",
    "teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_cleaned.csv')\n",
    "teams_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_post_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_10_years = awards_players_cleaned[awards_players_cleaned['year'] != 11]\n",
    "coaches__10_years = coaches_cleaned[coaches_cleaned['year'] != 11]\n",
    "players_teams_10_years = players_teams_cleaned[players_teams_cleaned['year'] != 11]\n",
    "series_post_10_years = series_post_cleaned[series_post_cleaned['year'] != 11]\n",
    "teams_10_years = teams_cleaned[teams_cleaned['year'] != 11]\n",
    "teams_post_10_years = teams_post_cleaned[teams_post_cleaned['year'] != 11]\n",
    "\n",
    "for df, name in [(awards_players_10_years, 'awards'), \n",
    "                 (coaches__10_years, 'coaches'),\n",
    "                 (players_teams_10_years, 'players'),\n",
    "                 (series_post_10_years, 'series'),\n",
    "                 (teams_10_years, 'teams'),\n",
    "                 (teams_post_10_years, 'teams_post')]:\n",
    "    if df['year'].max() != 10:\n",
    "        print(f\"Warning: {name} contains data beyond year 10\")\n",
    "\n",
    "awards_players_10_years.to_csv('../data/Season_11/awards_players_10_years.csv', index=False)\n",
    "coaches__10_years.to_csv('../data/Season_11/coaches_10_years.csv', index=False)\n",
    "players_cleaned.to_csv('../data/Season_11/players_10_years.csv', index=False)\n",
    "players_teams_10_years.to_csv('../data/Season_11/players_teams_10_years.csv', index=False)\n",
    "series_post_10_years.to_csv('../data/Season_11/series_post_10_years.csv', index=False)\n",
    "teams_10_years.to_csv('../data/Season_11/teams_10_years.csv', index=False)\n",
    "teams_post_10_years.to_csv('../data/Season_11/teams_post_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.5 Calculated Overalls from 10 years**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the all-time overall averages for players, coaches over the last 10 years by grouping the data by playerID/coachID and computing the mean of their OVERALL ratings. This provided a better way to visualize all performance data received. We also calculated an average overall for rookies and an average overall for rookie coaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_overall_avg = players_teams_10_years.groupby('playerID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "players_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "players_overall_avg['OVERALL_ALL_TIME'] = players_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "players_overall_avg.to_csv('../data/Season_11/players_overall_all_time_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_players = players_teams_10_years[players_teams_10_years['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_avg = rookie_players['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_avg_df = pd.DataFrame({'rookie_overall_avg': [rookie_overall_avg]})\n",
    "\n",
    "rookie_overall_avg_df.to_csv('../data/Season_11/rookie_overall_avg_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_coaches = coaches__10_years[coaches__10_years['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_coaches_avg = rookie_coaches['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_coaches_avg_df = pd.DataFrame({'rookie_overall_coaches_avg': [rookie_overall_coaches_avg]})\n",
    "\n",
    "rookie_overall_coaches_avg_df.to_csv('../data/Season_11/rookie_overall_coaches_avg_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_overall_avg = coaches__10_years.groupby('coachID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "coaches_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "coaches_overall_avg['OVERALL_ALL_TIME'] = coaches_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "coaches_overall_avg.to_csv('../data/Season_11/coaches_overall_all_time_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.6 Add overalls calculated from 10 years to the 11th year players and coach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterward, given the lineups for Year 11 and the overalls of all players/coaches from the previous 10 years, we added the overalls to the lineups to provide an overview of the team quality in Year 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_teams = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "# players_overall_all_time_10_years = pd.read_csv('../data/Season_11/players_overall_all_time_10_years.csv')\n",
    "\n",
    "# rookie_avg = 5.6 \n",
    "\n",
    "# players_teams = players_teams.merge(\n",
    "#     players_overall_all_time_10_years[['playerID', 'OVERALL_ALL_TIME']],\n",
    "#     on='playerID',\n",
    "#     how='left'\n",
    "# ).fillna({'OVERALL_ALL_TIME': rookie_avg})\n",
    "\n",
    "# players_teams.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "# players_teams.to_csv('../data/Season_11/players_teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coaches = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "# coaches_overall_all_time_10_years = pd.read_csv('../data/Season_11/coaches_overall_all_time_10_years.csv')\n",
    "\n",
    "# rookie_avg_coach = 9.0 \n",
    "\n",
    "# coaches = coaches.merge(\n",
    "#     coaches_overall_all_time_10_years[['coachID', 'OVERALL_ALL_TIME']],\n",
    "#     on='coachID',\n",
    "#     how='left'\n",
    "# ).fillna({'OVERALL_ALL_TIME': rookie_avg_coach})\n",
    "\n",
    "# coaches.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "# coaches.to_csv('../data/Season_11/coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.7 Given the teams players composition and their respective overalls calculate the team overall (mean of all players)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using the player lineups and their respective overalls, we decided to create a team_overall that summarizes the average overall of each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "\n",
    "team_overall = players.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall['overall_team'] = team_overall['OVERALL'].round(1)\n",
    "\n",
    "team_overall = team_overall.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall.to_csv('../data/Season_11/team_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.8 Given the team coaches and their respective overalls calculate the coach overall (mean of all coaches(1 or more than 1))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we did the same for coaches, as a team may have had more than one coach throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "\n",
    "team_overall_coaches = coaches.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall_coaches['overall_team_coach'] = team_overall_coaches['OVERALL'].round(1)\n",
    "\n",
    "team_overall_coaches = team_overall_coaches.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall_coaches.to_csv('../data/Season_11/team_overall_coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **V.9 Implementing Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained several models (SVM, Decision Tree, Random Forest, Logistic Regression, and KNN) to predict playoff teams for Year 11 based on data from the past 10 years. Features like win rates, points, and coach/player overalls were used. After training, the best model was selected based on accuracy, and its adjusted predictions for playoff were outputted, sorted by team ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n",
      "Training Accuracy: 76.30%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training Decision Tree...\n",
      "Training Accuracy: 78.52%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training Random Forest...\n",
      "Training Accuracy: 93.33%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training Logistic Regression...\n",
      "Training Accuracy: 71.11%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training KNN...\n",
      "Training Accuracy: 73.33%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Best Model: Random Forest\n",
      "Training Accuracy: 93.33%\n",
      "\n",
      "Final predictions (sorted by tmID):\n",
      " tmID Playoff\n",
      "    0    0.57\n",
      "    2    0.57\n",
      "    4    0.76\n",
      "    7    0.76\n",
      "    8    0.63\n",
      "   10    0.52\n",
      "   11    0.70\n",
      "   13    0.77\n",
      "   16    0.73\n",
      "   17    0.75\n",
      "   19    0.63\n",
      "   20    0.62\n",
      "\n",
      "Sum of probabilities: 8.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "teams_10_years = pd.read_csv('../data/Season_11/teams_10_years.csv')\n",
    "players_teams_10_years = pd.read_csv('../data/Season_11/players_teams_10_years.csv')\n",
    "coaches_10_years = pd.read_csv('../data/Season_11/coaches_10_years.csv')\n",
    "teams_year_11 = pd.read_csv('../data/Season_11/teams.csv')\n",
    "players_teams_11 = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "coaches_11 = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "\n",
    "def create_features_for_team(team_data, teams_history, players_teams_data, coaches_data, year):\n",
    "    features = {\n",
    "        'won': team_data['won'] if 'won' in team_data else 0,\n",
    "        'lost': team_data['lost'] if 'lost' in team_data else 0,\n",
    "        'o_pts': team_data['o_pts'] if 'o_pts' in team_data else 0,\n",
    "        'd_pts': team_data['d_pts'] if 'd_pts' in team_data else 0,\n",
    "        'o_reb': team_data['o_reb'] if 'o_reb' in team_data else 0,\n",
    "        'd_reb': team_data['d_reb'] if 'd_reb' in team_data else 0,\n",
    "        'confID': team_data['confID']\n",
    "    }\n",
    "    \n",
    "    team_history_data = teams_history[\n",
    "        (teams_history['tmID'] == team_data['tmID']) & \n",
    "        (teams_history['year'] <= year)\n",
    "    ].sort_values('year')\n",
    "    \n",
    "    if len(team_history_data) > 0:\n",
    "        features['win_rate_3yr'] = team_history_data['won'].tail(3).mean()\n",
    "        features['playoff_rate_3yr'] = team_history_data['playoff'].tail(3).mean()\n",
    "        features['points_diff_3yr'] = (team_history_data['o_pts'] - team_history_data['d_pts']).tail(3).mean()\n",
    "    else:\n",
    "        features['win_rate_3yr'] = 0\n",
    "        features['playoff_rate_3yr'] = 0\n",
    "        features['points_diff_3yr'] = 0\n",
    "    \n",
    "    team_players = players_teams_data[\n",
    "        players_teams_data['tmID'] == team_data['tmID']\n",
    "    ]\n",
    "    features['player_overall_avg'] = team_players['OVERALL'].mean() if len(team_players) > 0 else 0\n",
    "    \n",
    "    team_coach = coaches_data[\n",
    "        coaches_data['tmID'] == team_data['tmID']\n",
    "    ]\n",
    "    features['coach_overall'] = team_coach['OVERALL'].mean() if len(team_coach) > 0 else 0\n",
    "    \n",
    "    return list(features.values())\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for year in range(1, 10):\n",
    "    current_year_teams = teams_10_years[teams_10_years['year'] == year]\n",
    "    next_year_teams = teams_10_years[teams_10_years['year'] == year + 1]\n",
    "    \n",
    "    for _, team in current_year_teams.iterrows():\n",
    "        if team['tmID'] in next_year_teams['tmID'].values:\n",
    "            features = create_features_for_team(\n",
    "                team, \n",
    "                teams_10_years, \n",
    "                players_teams_10_years[players_teams_10_years['year'] == year],\n",
    "                coaches_10_years[coaches_10_years['year'] == year],\n",
    "                year\n",
    "            )\n",
    "            X_train.append(features)\n",
    "            next_year_playoff = next_year_teams[next_year_teams['tmID'] == team['tmID']]['playoff'].iloc[0]\n",
    "            y_train.append(next_year_playoff)\n",
    "\n",
    "year_10_teams = teams_10_years[teams_10_years['year'] == 10]\n",
    "for _, team in year_10_teams.iterrows():\n",
    "    features = create_features_for_team(\n",
    "        team,\n",
    "        teams_10_years,\n",
    "        players_teams_10_years[players_teams_10_years['year'] == 10],\n",
    "        coaches_10_years[coaches_10_years['year'] == 10],\n",
    "        10\n",
    "    )\n",
    "    X_train.append(features)\n",
    "    y_train.append(team['playoff'])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_predict = []\n",
    "for _, team in teams_year_11.iterrows():\n",
    "    features = create_features_for_team(\n",
    "        team,\n",
    "        teams_10_years,\n",
    "        players_teams_11,\n",
    "        coaches_11,\n",
    "        11\n",
    "    )\n",
    "    X_predict.append(features)\n",
    "X_predict = np.array(X_predict)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_predict_scaled = scaler.transform(X_predict)\n",
    "\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', probability=True, C=0.5, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        C=0.8,\n",
    "        max_iter=1000, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "model_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train_scaled)) * 100\n",
    "    \n",
    "    probs = model.predict_proba(X_predict_scaled)[:, 1]\n",
    "    \n",
    "    probs_adjusted = 8 * (1 - probs) / np.sum(1 - probs)\n",
    "\n",
    "    model_predictions[name] = {\n",
    "        'training_accuracy': train_accuracy,\n",
    "        'probabilities': dict(zip(teams_year_11['tmID'], probs_adjusted))\n",
    "    }\n",
    "    \n",
    "    print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Sum of probabilities: {np.sum(probs_adjusted):.2f}\")\n",
    "\n",
    "best_model = max(model_predictions.items(), key=lambda x: x[1]['training_accuracy'])\n",
    "print(f\"\\nBest Model: {best_model[0]}\")\n",
    "print(f\"Training Accuracy: {best_model[1]['training_accuracy']:.2f}%\")\n",
    "\n",
    "final_predictions = pd.DataFrame({\n",
    "    'tmID': teams_year_11['tmID'],\n",
    "    'Playoff': [best_model[1]['probabilities'][tmID] for tmID in teams_year_11['tmID']]\n",
    "})\n",
    "\n",
    "final_predictions = final_predictions.sort_values('tmID')\n",
    "final_predictions['Playoff'] = final_predictions['Playoff'].apply(lambda x: \"{:.2f}\".format(x))\n",
    "\n",
    "print(\"\\nFinal predictions (sorted by tmID):\")\n",
    "print(final_predictions.to_string(index=False))\n",
    "\n",
    "prob_sum = sum(float(x) for x in final_predictions['Playoff'])\n",
    "print(f\"\\nSum of probabilities: {prob_sum:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we decided to use the SVM model, a new model different from the previously best-performing model. We incorporated team and coach overalls, average win/loss ratio from the past 10 years, total playoff appearances, and average rank (with higher ranks being worse for the team). Afterward, we calculated binary playoff probabilities and saved the output to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Training complete.\n",
      "\n",
      "Conference classification (Binary Playoff):\n",
      "    tmID  Playoff\n",
      "2      4        1\n",
      "3      7        1\n",
      "6     11        1\n",
      "10    19        1\n",
      "0      0        0\n",
      "1      2        0\n",
      "5     10        1\n",
      "7     13        1\n",
      "8     16        1\n",
      "9     17        1\n",
      "4      8        0\n",
      "11    20        0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data_team = pd.read_csv('../data/Season_11/team_overall.csv')\n",
    "data_coach = pd.read_csv('../data/Season_11/team_overall_coaches.csv')\n",
    "data_conference = pd.read_csv('../data/Season_11/teams.csv')\n",
    "data_historic = pd.read_csv('../data/Season_11/teams_10_years.csv')\n",
    "\n",
    "data = data_team.merge(data_coach, on=\"tmID\").merge(data_conference, on=\"tmID\")\n",
    "\n",
    "data_historic['win_loss_ratio'] = data_historic['won'] / (data_historic['won'] + data_historic['lost'])\n",
    "win_loss_avg = data_historic.groupby('tmID')['win_loss_ratio'].mean().reset_index()\n",
    "win_loss_avg.rename(columns={'win_loss_ratio': 'avg_win_loss_ratio'}, inplace=True)\n",
    "\n",
    "data_historic['playoff_count'] = data_historic['playoff'].apply(lambda x: 1 if x == 1 else 0)\n",
    "playoff_count = data_historic.groupby('tmID')['playoff_count'].sum().reset_index()\n",
    "playoff_count.rename(columns={'playoff_count': 'total_playoffs'}, inplace=True)\n",
    "\n",
    "rank_avg = data_historic.groupby('tmID')['rank'].mean().reset_index()\n",
    "rank_avg.rename(columns={'rank': 'avg_rank'}, inplace=True)\n",
    "\n",
    "data = data.merge(win_loss_avg, on='tmID', how='left')\\\n",
    "           .merge(playoff_count, on='tmID', how='left')\\\n",
    "           .merge(rank_avg, on='tmID', how='left')\n",
    "\n",
    "data['avg_win_loss_ratio'] = data['avg_win_loss_ratio'].fillna(0)\n",
    "data['total_playoffs'] = data['total_playoffs'].fillna(0)\n",
    "data['avg_rank'] = data['avg_rank'].fillna(0)\n",
    "\n",
    "data[\"weighted_overall\"] = (\n",
    "    8 * data[\"overall_team\"] + \n",
    "    2 * data[\"overall_team_coach\"] + \n",
    "    1 * data[\"avg_win_loss_ratio\"] +  \n",
    "    1 * data[\"total_playoffs\"] +      \n",
    "    -2 * data[\"avg_rank\"]              \n",
    ")\n",
    "\n",
    "data[\"Playoff\"] = 0\n",
    "for conf in data[\"confID\"].unique():\n",
    "    conf_teams = data[data[\"confID\"] == conf]\n",
    "    top_teams = conf_teams.nlargest(4, \"weighted_overall\")\n",
    "    data.loc[top_teams.index, \"Playoff\"] = 1\n",
    "\n",
    "X = data[[\"overall_team\", \"overall_team_coach\", \"confID\", \"avg_win_loss_ratio\", \"total_playoffs\", \"avg_rank\"]]\n",
    "y = data[\"Playoff\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Training SVM...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "probs = model.predict_proba(X)[:, 1]\n",
    "data['Playoff_Probability'] = probs\n",
    "\n",
    "data[\"Playoff\"] = 0\n",
    "\n",
    "for conf in data[\"confID\"].unique():\n",
    "    conf_teams = data[data[\"confID\"] == conf]\n",
    "    top_teams = conf_teams.nlargest(4, \"Playoff_Probability\")\n",
    "    data.loc[top_teams.index, \"Playoff\"] = 1\n",
    "\n",
    "final_result = data[[\"tmID\", \"confID\", \"weighted_overall\", \"Playoff\"]].sort_values(\n",
    "    by=[\"confID\", \"Playoff\"], ascending=[True, False]\n",
    ")\n",
    "\n",
    "print(\"\\nConference classification (Binary Playoff):\")\n",
    "print(final_result[[\"tmID\", \"Playoff\"]])\n",
    "\n",
    "final_output = final_result[[\"tmID\", \"Playoff\"]]\n",
    "final_output.to_csv('../data/Season_11/playoff_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we performed a reverse mapping to format the output CSV as required for the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_teams = {\n",
    "     'ATL': 0, 'CHI': 2, 'CON': 4, 'IND': 7, \n",
    "     'LAS': 8, 'MIN': 10, 'NYL': 11, 'PHO': 13, \n",
    "     'SAS': 16, 'SEA': 17, 'WAS': 19, 'TUL': 20\n",
    "}\n",
    "\n",
    "reverse_map_teams = {v: k for k, v in map_teams.items()}\n",
    "\n",
    "final_output = pd.read_csv('../data/Season_11/playoff_predictions.csv')\n",
    "\n",
    "final_output[\"tmID\"] = final_output[\"tmID\"].map(reverse_map_teams)\n",
    "final_output = final_output.sort_values(by=\"tmID\")\n",
    "\n",
    "final_output.to_csv('../data/Season_11/playoff_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a prediction error of 4 during the 5 days of the competition. Considering the theoretical maximum error is 12 and the best is 0, we are happy with the results we achieved. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
