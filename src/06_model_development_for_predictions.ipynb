{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare predictions for the 11th year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data on 11th year files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "coaches_11th = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "players_teams_11th = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "teams_11th = pd.read_csv('../data/Season_11/teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coaches_11th = coaches_11th.drop(columns=['stint', 'lgID', 'year'])\n",
    "# players_teams_11th = players_teams_11th.drop(columns=['stint', 'lgID', 'year'])\n",
    "# teams_11th = teams_11th.drop(columns=['lgID', 'franchID', 'year', 'name', 'arena'])\n",
    "\n",
    "# coaches_11th.to_csv('../data/Season_11/coaches.csv', index=False)\n",
    "# players_teams_11th.to_csv('../data/Season_11/players_teams.csv', index=False)\n",
    "# teams_11th.to_csv('../data/Season_11/teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maping categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_teams = {\n",
    "#     'ATL': 0, 'CHI': 2, 'CON': 4, 'IND': 7, \n",
    "#     'LAS': 8, 'MIN': 10, 'NYL': 11, 'PHO': 13, \n",
    "#     'SAS': 16, 'SEA': 17, 'WAS': 19, 'TUL': 20\n",
    "# }\n",
    "\n",
    "# map_conf = {\n",
    "#   'EA': 0, 'WE': 1\n",
    "# }\n",
    "\n",
    "# coaches_11th['tmID'] = coaches_11th['tmID'].map(map_teams)\n",
    "# players_teams_11th['tmID'] = players_teams_11th['tmID'].map(map_teams)\n",
    "# teams_11th['tmID'] = teams_11th['tmID'].map(map_teams)\n",
    "# teams_11th['confID'] = teams_11th['confID'].map(map_conf)\n",
    "\n",
    "# coaches_11th.to_csv('../data/Season_11/coaches.csv', index=False)\n",
    "# players_teams_11th.to_csv('../data/Season_11/players_teams.csv', index=False)\n",
    "# teams_11th.to_csv('../data/Season_11/teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from the past 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/awards_players_cleaned.csv')\n",
    "coaches_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/coaches_cleaned.csv')\n",
    "players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_cleaned.csv')\n",
    "players_teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_teams_cleaned.csv')\n",
    "series_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/series_post_cleaned.csv')\n",
    "teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_cleaned.csv')\n",
    "teams_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_post_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_10_years = awards_players_cleaned[awards_players_cleaned['year'] != 11]\n",
    "coaches__10_years = coaches_cleaned[coaches_cleaned['year'] != 11]\n",
    "players_teams_10_years = players_teams_cleaned[players_teams_cleaned['year'] != 11]\n",
    "series_post_10_years = series_post_cleaned[series_post_cleaned['year'] != 11]\n",
    "teams_10_years = teams_cleaned[teams_cleaned['year'] != 11]\n",
    "teams_post_10_years = teams_post_cleaned[teams_post_cleaned['year'] != 11]\n",
    "\n",
    "for df, name in [(awards_players_10_years, 'awards'), \n",
    "                 (coaches__10_years, 'coaches'),\n",
    "                 (players_teams_10_years, 'players'),\n",
    "                 (series_post_10_years, 'series'),\n",
    "                 (teams_10_years, 'teams'),\n",
    "                 (teams_post_10_years, 'teams_post')]:\n",
    "    if df['year'].max() != 10:\n",
    "        print(f\"Warning: {name} contains data beyond year 10\")\n",
    "\n",
    "awards_players_10_years.to_csv('../data/Season_11/awards_players_10_years.csv', index=False)\n",
    "coaches__10_years.to_csv('../data/Season_11/coaches_10_years.csv', index=False)\n",
    "players_cleaned.to_csv('../data/Season_11/players_10_years.csv', index=False)\n",
    "players_teams_10_years.to_csv('../data/Season_11/players_teams_10_years.csv', index=False)\n",
    "series_post_10_years.to_csv('../data/Season_11/series_post_10_years.csv', index=False)\n",
    "teams_10_years.to_csv('../data/Season_11/teams_10_years.csv', index=False)\n",
    "teams_post_10_years.to_csv('../data/Season_11/teams_post_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overalls from 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_overall_avg = players_teams_10_years.groupby('playerID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "players_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "players_overall_avg['OVERALL_ALL_TIME'] = players_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "players_overall_avg.to_csv('../data/Season_11/players_overall_all_time_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_players = players_teams_10_years[players_teams_10_years['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_avg = rookie_players['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_avg_df = pd.DataFrame({'rookie_overall_avg': [rookie_overall_avg]})\n",
    "\n",
    "rookie_overall_avg_df.to_csv('../data/Season_11/rookie_overall_avg_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_coaches = coaches__10_years[coaches__10_years['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_coaches_avg = rookie_coaches['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_coaches_avg_df = pd.DataFrame({'rookie_overall_coaches_avg': [rookie_overall_coaches_avg]})\n",
    "\n",
    "rookie_overall_coaches_avg_df.to_csv('../data/Season_11/rookie_overall_coaches_avg_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_overall_avg = coaches__10_years.groupby('coachID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "coaches_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "coaches_overall_avg['OVERALL_ALL_TIME'] = coaches_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "coaches_overall_avg.to_csv('../data/Season_11/coaches_overall_all_time_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add overalls calculated from 10 years to the 11th year players and coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_teams = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "# players_overall_all_time_10_years = pd.read_csv('../data/Season_11/players_overall_all_time_10_years.csv')\n",
    "\n",
    "# rookie_avg = 5.6 \n",
    "\n",
    "# players_teams = players_teams.merge(\n",
    "#     players_overall_all_time_10_years[['playerID', 'OVERALL_ALL_TIME']],\n",
    "#     on='playerID',\n",
    "#     how='left'\n",
    "# ).fillna({'OVERALL_ALL_TIME': rookie_avg})\n",
    "\n",
    "# players_teams.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "# players_teams.to_csv('../data/Season_11/players_teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coaches = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "# coaches_overall_all_time_10_years = pd.read_csv('../data/Season_11/coaches_overall_all_time_10_years.csv')\n",
    "\n",
    "# rookie_avg_coach = 9.0 \n",
    "\n",
    "# coaches = coaches.merge(\n",
    "#     coaches_overall_all_time_10_years[['coachID', 'OVERALL_ALL_TIME']],\n",
    "#     on='coachID',\n",
    "#     how='left'\n",
    "# ).fillna({'OVERALL_ALL_TIME': rookie_avg_coach})\n",
    "\n",
    "# coaches.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "# coaches.to_csv('../data/Season_11/coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the teams players composition and their respective overalls calculate the team overall (mean of all players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "\n",
    "team_overall = players.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall['overall_team'] = team_overall['OVERALL'].round(1)\n",
    "\n",
    "team_overall = team_overall.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall.to_csv('../data/Season_11/team_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the team coaches and their respective overalls calculate the coach overall (mean of all coaches(1 or more than 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "\n",
    "team_overall_coaches = coaches.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall_coaches['overall_team_coach'] = team_overall_coaches['OVERALL'].round(1)\n",
    "\n",
    "team_overall_coaches = team_overall_coaches.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall_coaches.to_csv('../data/Season_11/team_overall_coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n",
      "Training Accuracy: 76.30%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training Decision Tree...\n",
      "Training Accuracy: 78.52%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training Random Forest...\n",
      "Training Accuracy: 93.33%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training Logistic Regression...\n",
      "Training Accuracy: 71.11%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Training KNN...\n",
      "Training Accuracy: 73.33%\n",
      "Sum of probabilities: 8.00\n",
      "\n",
      "Best Model: Random Forest\n",
      "Training Accuracy: 93.33%\n",
      "\n",
      "Final predictions (sorted by tmID):\n",
      " tmID Playoff\n",
      "    0    0.57\n",
      "    2    0.57\n",
      "    4    0.76\n",
      "    7    0.76\n",
      "    8    0.63\n",
      "   10    0.52\n",
      "   11    0.70\n",
      "   13    0.77\n",
      "   16    0.73\n",
      "   17    0.75\n",
      "   19    0.63\n",
      "   20    0.62\n",
      "\n",
      "Sum of probabilities: 8.01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load data\n",
    "teams_10_years = pd.read_csv('../data/Season_11/teams_10_years.csv')\n",
    "players_teams_10_years = pd.read_csv('../data/Season_11/players_teams_10_years.csv')\n",
    "coaches_10_years = pd.read_csv('../data/Season_11/coaches_10_years.csv')\n",
    "teams_year_11 = pd.read_csv('../data/Season_11/teams.csv')\n",
    "players_teams_11 = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "coaches_11 = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "\n",
    "def create_features_for_team(team_data, teams_history, players_teams_data, coaches_data, year):\n",
    "    features = {\n",
    "        'won': team_data['won'] if 'won' in team_data else 0,\n",
    "        'lost': team_data['lost'] if 'lost' in team_data else 0,\n",
    "        'o_pts': team_data['o_pts'] if 'o_pts' in team_data else 0,\n",
    "        'd_pts': team_data['d_pts'] if 'd_pts' in team_data else 0,\n",
    "        'o_reb': team_data['o_reb'] if 'o_reb' in team_data else 0,\n",
    "        'd_reb': team_data['d_reb'] if 'd_reb' in team_data else 0,\n",
    "        'confID': team_data['confID']\n",
    "    }\n",
    "    \n",
    "    # Verifique se há histórico para a equipe\n",
    "    team_history_data = teams_history[\n",
    "        (teams_history['tmID'] == team_data['tmID']) & \n",
    "        (teams_history['year'] <= year)\n",
    "    ].sort_values('year')\n",
    "    \n",
    "    if len(team_history_data) > 0:\n",
    "        # Se a equipe tem dados históricos, calcule as médias de 3 anos\n",
    "        features['win_rate_3yr'] = team_history_data['won'].tail(3).mean()\n",
    "        features['playoff_rate_3yr'] = team_history_data['playoff'].tail(3).mean()\n",
    "        features['points_diff_3yr'] = (team_history_data['o_pts'] - team_history_data['d_pts']).tail(3).mean()\n",
    "    else:\n",
    "        # Se a equipe não tem dados históricos (nova equipe), atribua valores padrão baixos\n",
    "        features['win_rate_3yr'] = 0\n",
    "        features['playoff_rate_3yr'] = 0\n",
    "        features['points_diff_3yr'] = 0\n",
    "    \n",
    "    # Dados do jogador\n",
    "    team_players = players_teams_data[\n",
    "        players_teams_data['tmID'] == team_data['tmID']\n",
    "    ]\n",
    "    features['player_overall_avg'] = team_players['OVERALL'].mean() if len(team_players) > 0 else 0\n",
    "    \n",
    "    # Dados do treinador\n",
    "    team_coach = coaches_data[\n",
    "        coaches_data['tmID'] == team_data['tmID']\n",
    "    ]\n",
    "    features['coach_overall'] = team_coach['OVERALL'].mean() if len(team_coach) > 0 else 0\n",
    "    \n",
    "    return list(features.values())\n",
    "\n",
    "# Prepare training data (years 1-10)\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for year in range(1, 10):\n",
    "    current_year_teams = teams_10_years[teams_10_years['year'] == year]\n",
    "    next_year_teams = teams_10_years[teams_10_years['year'] == year + 1]\n",
    "    \n",
    "    for _, team in current_year_teams.iterrows():\n",
    "        if team['tmID'] in next_year_teams['tmID'].values:\n",
    "            features = create_features_for_team(\n",
    "                team, \n",
    "                teams_10_years, \n",
    "                players_teams_10_years[players_teams_10_years['year'] == year],\n",
    "                coaches_10_years[coaches_10_years['year'] == year],\n",
    "                year\n",
    "            )\n",
    "            X_train.append(features)\n",
    "            next_year_playoff = next_year_teams[next_year_teams['tmID'] == team['tmID']]['playoff'].iloc[0]\n",
    "            y_train.append(next_year_playoff)\n",
    "\n",
    "# Add year 10 data for training\n",
    "year_10_teams = teams_10_years[teams_10_years['year'] == 10]\n",
    "for _, team in year_10_teams.iterrows():\n",
    "    features = create_features_for_team(\n",
    "        team,\n",
    "        teams_10_years,\n",
    "        players_teams_10_years[players_teams_10_years['year'] == 10],\n",
    "        coaches_10_years[coaches_10_years['year'] == 10],\n",
    "        10\n",
    "    )\n",
    "    X_train.append(features)\n",
    "    y_train.append(team['playoff'])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Prepare prediction data for year 11\n",
    "X_predict = []\n",
    "for _, team in teams_year_11.iterrows():\n",
    "    features = create_features_for_team(\n",
    "        team,\n",
    "        teams_10_years,\n",
    "        players_teams_11,\n",
    "        coaches_11,\n",
    "        11\n",
    "    )\n",
    "    X_predict.append(features)\n",
    "X_predict = np.array(X_predict)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_predict_scaled = scaler.transform(X_predict)\n",
    "\n",
    "# Initialize models with same parameters as year 10\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', probability=True, C=0.5, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        max_depth=3,\n",
    "        min_samples_leaf=4,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        C=0.8,\n",
    "        max_iter=1000, \n",
    "        random_state=42\n",
    "    ),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "# Train models and get predictions\n",
    "model_predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get training accuracy\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train_scaled)) * 100\n",
    "    \n",
    "    # Get probabilities for year 11\n",
    "    probs = model.predict_proba(X_predict_scaled)[:, 1]\n",
    "    \n",
    "    probs_adjusted = 8 * (1 - probs) / np.sum(1 - probs)\n",
    "\n",
    "    # Store results\n",
    "    model_predictions[name] = {\n",
    "        'training_accuracy': train_accuracy,\n",
    "        'probabilities': dict(zip(teams_year_11['tmID'], probs_adjusted))\n",
    "    }\n",
    "    \n",
    "    print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Sum of probabilities: {np.sum(probs_adjusted):.2f}\")\n",
    "\n",
    "# Find best model based on training accuracy\n",
    "best_model = max(model_predictions.items(), key=lambda x: x[1]['training_accuracy'])\n",
    "print(f\"\\nBest Model: {best_model[0]}\")\n",
    "print(f\"Training Accuracy: {best_model[1]['training_accuracy']:.2f}%\")\n",
    "\n",
    "# Create final predictions CSV with the best model's predictions\n",
    "final_predictions = pd.DataFrame({\n",
    "    'tmID': teams_year_11['tmID'],\n",
    "    'Playoff': [best_model[1]['probabilities'][tmID] for tmID in teams_year_11['tmID']]\n",
    "})\n",
    "\n",
    "# Sort by tmID and format probabilities\n",
    "final_predictions = final_predictions.sort_values('tmID')\n",
    "final_predictions['Playoff'] = final_predictions['Playoff'].apply(lambda x: \"{:.2f}\".format(x))\n",
    "\n",
    "# Save predictions\n",
    "final_predictions.to_csv('../data/Season_11/playoff_predictions.csv', index=False)\n",
    "\n",
    "print(\"\\nFinal predictions (sorted by tmID):\")\n",
    "print(final_predictions.to_string(index=False))\n",
    "\n",
    "# Verify sum of probabilities\n",
    "prob_sum = sum(float(x) for x in final_predictions['Playoff'])\n",
    "print(f\"\\nSum of probabilities: {prob_sum:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_teams = {\n",
    "    'ATL': 0, 'CHI': 2, 'CON': 4, 'IND': 7, \n",
    "    'LAS': 8, 'MIN': 10, 'NYL': 11, 'PHO': 13, \n",
    "    'SAS': 16, 'SEA': 17, 'WAS': 19, 'TUL': 20\n",
    "}\n",
    "\n",
    "reverse_map_teams = {v: k for k, v in map_teams.items()}\n",
    "\n",
    "final_predictions = pd.read_csv('../data/Season_11/playoff_predictions.csv')\n",
    "\n",
    "final_predictions['tmID'] = final_predictions['tmID'].map(reverse_map_teams)\n",
    "final_predictions = final_predictions.sort_values(by='tmID')\n",
    "\n",
    "final_predictions.to_csv('../data/Season_11/playoff_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicitons using only overalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conference classification:\n",
      "    tmID  confID  weighted_overall  playoff\n",
      "0      0       0              21.8        0\n",
      "1      2       0              23.2        0\n",
      "2      4       0              26.0        1\n",
      "3      7       0              27.7        1\n",
      "6     11       0              26.7        1\n",
      "10    19       0              23.5        1\n",
      "5     10       1              29.0        1\n",
      "4      8       1              27.4        1\n",
      "7     13       1              29.6        1\n",
      "8     16       1              26.3        1\n",
      "9     17       1              25.8        0\n",
      "11    20       1              22.6        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the data\n",
    "data_team = pd.read_csv('../data/Season_11/team_overall.csv')  # Player averages\n",
    "data_coach = pd.read_csv('../data/Season_11/team_overall_coaches.csv')  # Coach averages\n",
    "data_conference = pd.read_csv('../data/Season_11/teams.csv')  # Conferences\n",
    "\n",
    "# Combine the data\n",
    "data = data_team.merge(data_coach, on=\"tmID\").merge(data_conference, on=\"tmID\")\n",
    "\n",
    "# Give more weight to the overall_team (2x)\n",
    "data[\"weighted_overall\"] = 2 * data[\"overall_team\"] + data[\"overall_team_coach\"]\n",
    "\n",
    "# Create the target variable (1 for the top 4 teams in each conference)\n",
    "data[\"playoff\"] = 0\n",
    "for conf in data[\"confID\"].unique():\n",
    "    conf_teams = data[data[\"confID\"] == conf]\n",
    "    top_teams = conf_teams.nlargest(4, \"weighted_overall\")\n",
    "    data.loc[top_teams.index, \"playoff\"] = 1\n",
    "\n",
    "# Normalize \"weighted_overall\" by conference\n",
    "data[\"conf_weighted_overall\"] = data.groupby(\"confID\")[\"weighted_overall\"].transform(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "\n",
    "# Separate independent and dependent variables\n",
    "X = data[[\"overall_team\", \"overall_team_coach\", \"confID\"]]\n",
    "y = data[\"playoff\"]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Create a pipeline with standardization and SVM\n",
    "model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "# Display the validation, now with adjusted probabilities\n",
    "validation = data[[\"tmID\", \"confID\", \"weighted_overall\", \"playoff\"]].sort_values(\n",
    "    by=[\"confID\"], ascending=[True]\n",
    ")\n",
    "\n",
    "# Display the validation\n",
    "print(\"\\nConference classification:\")\n",
    "print(validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
