{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare predictions for the 11th year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data on 11th year files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "coaches_11th = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "players_teams_11th = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "teams_11th = pd.read_csv('../data/Season_11/teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coaches_11th = coaches_11th.drop(columns=['stint', 'lgID', 'year'])\n",
    "# players_teams_11th = players_teams_11th.drop(columns=['stint', 'lgID', 'year'])\n",
    "# teams_11th = teams_11th.drop(columns=['lgID', 'franchID', 'year', 'name', 'arena'])\n",
    "\n",
    "# coaches_11th.to_csv('../data/Season_11/coaches.csv', index=False)\n",
    "# players_teams_11th.to_csv('../data/Season_11/players_teams.csv', index=False)\n",
    "# teams_11th.to_csv('../data/Season_11/teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maping categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_teams = {\n",
    "#     'ATL': 0, 'CHI': 2, 'CON': 4, 'IND': 7, \n",
    "#     'LAS': 8, 'MIN': 10, 'NYL': 11, 'PHO': 13, \n",
    "#     'SAS': 16, 'SEA': 17, 'WAS': 19, 'TUL': 20\n",
    "# }\n",
    "\n",
    "# map_conf = {\n",
    "#   'EA': 0, 'WE': 1\n",
    "# }\n",
    "\n",
    "# coaches_11th['tmID'] = coaches_11th['tmID'].map(map_teams)\n",
    "# players_teams_11th['tmID'] = players_teams_11th['tmID'].map(map_teams)\n",
    "# teams_11th['tmID'] = teams_11th['tmID'].map(map_teams)\n",
    "# teams_11th['confID'] = teams_11th['confID'].map(map_conf)\n",
    "\n",
    "# coaches_11th.to_csv('../data/Season_11/coaches.csv', index=False)\n",
    "# players_teams_11th.to_csv('../data/Season_11/players_teams.csv', index=False)\n",
    "# teams_11th.to_csv('../data/Season_11/teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from the past 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/awards_players_cleaned.csv')\n",
    "coaches_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/coaches_cleaned.csv')\n",
    "players_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_cleaned.csv')\n",
    "players_teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/players_teams_cleaned.csv')\n",
    "series_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/series_post_cleaned.csv')\n",
    "teams_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_cleaned.csv')\n",
    "teams_post_cleaned = pd.read_csv('../data/basketballPlayoffs_cleaned/teams_post_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_10_years = awards_players_cleaned[awards_players_cleaned['year'] != 11]\n",
    "coaches__10_years = coaches_cleaned[coaches_cleaned['year'] != 11]\n",
    "players_teams_10_years = players_teams_cleaned[players_teams_cleaned['year'] != 11]\n",
    "series_post_10_years = series_post_cleaned[series_post_cleaned['year'] != 11]\n",
    "teams_10_years = teams_cleaned[teams_cleaned['year'] != 11]\n",
    "teams_post_10_years = teams_post_cleaned[teams_post_cleaned['year'] != 11]\n",
    "\n",
    "for df, name in [(awards_players_10_years, 'awards'), \n",
    "                 (coaches__10_years, 'coaches'),\n",
    "                 (players_teams_10_years, 'players'),\n",
    "                 (series_post_10_years, 'series'),\n",
    "                 (teams_10_years, 'teams'),\n",
    "                 (teams_post_10_years, 'teams_post')]:\n",
    "    if df['year'].max() != 10:\n",
    "        print(f\"Warning: {name} contains data beyond year 10\")\n",
    "\n",
    "awards_players_10_years.to_csv('../data/Season_11/awards_players_10_years.csv', index=False)\n",
    "coaches__10_years.to_csv('../data/Season_11/coaches_10_years.csv', index=False)\n",
    "players_cleaned.to_csv('../data/Season_11/players_10_years.csv', index=False)\n",
    "players_teams_10_years.to_csv('../data/Season_11/players_teams_10_years.csv', index=False)\n",
    "series_post_10_years.to_csv('../data/Season_11/series_post_10_years.csv', index=False)\n",
    "teams_10_years.to_csv('../data/Season_11/teams_10_years.csv', index=False)\n",
    "teams_post_10_years.to_csv('../data/Season_11/teams_post_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overalls from 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_overall_avg = players_teams_10_years.groupby('playerID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "players_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "players_overall_avg['OVERALL_ALL_TIME'] = players_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "players_overall_avg.to_csv('../data/Season_11/players_overall_all_time_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_players = players_teams_10_years[players_teams_10_years['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_avg = rookie_players['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_avg_df = pd.DataFrame({'rookie_overall_avg': [rookie_overall_avg]})\n",
    "\n",
    "rookie_overall_avg_df.to_csv('../data/Season_11/rookie_overall_avg_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookie_coaches = coaches__10_years[coaches__10_years['is_rookie'] == 1]\n",
    "\n",
    "rookie_overall_coaches_avg = rookie_coaches['OVERALL'].mean().round(1)\n",
    "\n",
    "rookie_overall_coaches_avg_df = pd.DataFrame({'rookie_overall_coaches_avg': [rookie_overall_coaches_avg]})\n",
    "\n",
    "rookie_overall_coaches_avg_df.to_csv('../data/Season_11/rookie_overall_coaches_avg_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_overall_avg = coaches__10_years.groupby('coachID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "coaches_overall_avg.rename(columns={'OVERALL': 'OVERALL_ALL_TIME'}, inplace=True)\n",
    "\n",
    "coaches_overall_avg['OVERALL_ALL_TIME'] = coaches_overall_avg['OVERALL_ALL_TIME'].round(1)\n",
    "\n",
    "coaches_overall_avg.to_csv('../data/Season_11/coaches_overall_all_time_10_years.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add overalls calculated from 10 years to the 11th year players and coach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_teams = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "# players_overall_all_time_10_years = pd.read_csv('../data/Season_11/players_overall_all_time_10_years.csv')\n",
    "\n",
    "# rookie_avg = 5.6 \n",
    "\n",
    "# players_teams = players_teams.merge(\n",
    "#     players_overall_all_time_10_years[['playerID', 'OVERALL_ALL_TIME']],\n",
    "#     on='playerID',\n",
    "#     how='left'\n",
    "# ).fillna({'OVERALL_ALL_TIME': rookie_avg})\n",
    "\n",
    "# players_teams.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "# players_teams.to_csv('../data/Season_11/players_teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coaches = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "# coaches_overall_all_time_10_years = pd.read_csv('../data/Season_11/coaches_overall_all_time_10_years.csv')\n",
    "\n",
    "# rookie_avg_coach = 9.0 \n",
    "\n",
    "# coaches = coaches.merge(\n",
    "#     coaches_overall_all_time_10_years[['coachID', 'OVERALL_ALL_TIME']],\n",
    "#     on='coachID',\n",
    "#     how='left'\n",
    "# ).fillna({'OVERALL_ALL_TIME': rookie_avg_coach})\n",
    "\n",
    "# coaches.rename(columns={'OVERALL_ALL_TIME': 'OVERALL'}, inplace=True)\n",
    "\n",
    "# coaches.to_csv('../data/Season_11/coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the teams players composition and their respective overalls calculate the team overall (mean of all players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv('../data/Season_11/players_teams.csv')\n",
    "\n",
    "team_overall = players.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall['overall_team'] = team_overall['OVERALL'].round(1)\n",
    "\n",
    "team_overall = team_overall.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall.to_csv('../data/Season_11/team_overall.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given the team coaches and their respective overalls calculate the coach overall (mean of all coaches(1 or more than 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches = pd.read_csv('../data/Season_11/coaches.csv')\n",
    "\n",
    "team_overall_coaches = coaches.groupby('tmID')['OVERALL'].mean().reset_index()\n",
    "\n",
    "team_overall_coaches['overall_team_coach'] = team_overall_coaches['OVERALL'].round(1)\n",
    "\n",
    "team_overall_coaches = team_overall_coaches.drop(columns=['OVERALL'])\n",
    "\n",
    "team_overall_coaches.to_csv('../data/Season_11/team_overall_coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Read data\n",
    "teams_10_years = pd.read_csv('../data/Season_11/teams_10_years.csv')\n",
    "players_teams_10_years = pd.read_csv('../data/Season_11/players_teams_10_years.csv')\n",
    "coaches__10_years = pd.read_csv('../data/Season_11/coaches_10_years.csv')\n",
    "teams_year_11 = pd.read_csv('../data/Season_11/teams.csv')\n",
    "teams_year_11 = teams_year_11[['tmID', 'confID']]\n",
    "\n",
    "# Feature creation function with NaN handling\n",
    "def create_features_for_team(team_data, teams_history, players_teams_data, coaches_data, year):\n",
    "    features = {\n",
    "        'won': team_data['won'] if 'won' in team_data else 0, \n",
    "        'lost': team_data['lost'] if 'lost' in team_data else 0,\n",
    "        'o_pts': team_data['o_pts'] if 'o_pts' in team_data else 0,\n",
    "        'd_pts': team_data['d_pts'] if 'd_pts' in team_data else 0,\n",
    "        'o_reb': team_data['o_reb'] if 'o_reb' in team_data else 0,\n",
    "        'd_reb': team_data['d_reb'] if 'd_reb' in team_data else 0,\n",
    "        'confID': team_data['confID'],\n",
    "        'is_new_team': 0\n",
    "    }\n",
    "    \n",
    "    # Calculate historical averages\n",
    "    team_history_data = teams_history[\n",
    "        (teams_history['tmID'] == team_data['tmID']) & \n",
    "        (teams_history['year'] <= year)\n",
    "    ].sort_values('year')\n",
    "    \n",
    "    if team_history_data.empty: \n",
    "        features['win_rate_3yr'] = 0  # Neutral fallback\n",
    "        features['playoff_rate_3yr'] = 0 \n",
    "        features['points_diff_3yr'] = 0 \n",
    "        features['is_new_team'] = 1  \n",
    "    else:\n",
    "        # 3-year rolling averages\n",
    "        features['win_rate_3yr'] = team_history_data['won'].tail(3).mean()\n",
    "        features['playoff_rate_3yr'] = team_history_data['playoff'].tail(3).mean()\n",
    "        features['points_diff_3yr'] = (team_history_data['o_pts'] - team_history_data['d_pts']).tail(3).mean()\n",
    "    \n",
    "    # Player stats\n",
    "    team_players = players_teams_data[\n",
    "        (players_teams_data['year'] == year) & \n",
    "        (players_teams_data['tmID'] == team_data['tmID'])\n",
    "    ]\n",
    "    features['player_overall_avg'] = team_players['OVERALL'].mean() if len(team_players) > 0 else 0\n",
    "    features['player_stamina_avg'] = team_players['overallSTAMINA'].mean() if len(team_players) > 0 else 0\n",
    "    features['player_defense_avg'] = team_players['overallDEFENSE'].mean() if len(team_players) > 0 else 0\n",
    "    features['player_offense_avg'] = team_players['overallOFFENSE'].mean() if len(team_players) > 0 else 0\n",
    "    \n",
    "    # Coach stats\n",
    "    team_coach = coaches_data[\n",
    "        (coaches_data['year'] == year) & \n",
    "        (coaches_data['tmID'] == team_data['tmID'])\n",
    "    ]\n",
    "    features['coach_overall'] = team_coach['OVERALL'].mean() if len(team_coach) > 0 else 0\n",
    "    \n",
    "    # Return features as a list\n",
    "    return list(features.values())\n",
    "\n",
    "# Prepare training and validation data (years 1-10)\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for year in range(1, 10):\n",
    "    current_year_teams = teams_10_years[teams_10_years['year'] == year]\n",
    "    next_year_teams = teams_10_years[teams_10_years['year'] == year + 1]\n",
    "    \n",
    "    for _, team in current_year_teams.iterrows():\n",
    "        # Only include teams that exist in the next year\n",
    "        if team['tmID'] in next_year_teams['tmID'].values:\n",
    "            features = create_features_for_team(team, teams_10_years, players_teams_10_years, coaches__10_years, year)\n",
    "            X_train.append(features)\n",
    "            \n",
    "            # Get next year's playoff status\n",
    "            next_year_playoff = next_year_teams[next_year_teams['tmID'] == team['tmID']]['playoff'].iloc[0]\n",
    "            y_train.append(next_year_playoff)\n",
    "\n",
    "year_10_teams = teams_10_years[teams_10_years['year'] == 10]\n",
    "for _, team in year_10_teams.iterrows():\n",
    "    features = create_features_for_team(team, teams_10_years, players_teams_10_years, coaches__10_years, 10)\n",
    "    X_val.append(features)\n",
    "    y_val.append(team['playoff'])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Handle NaN values (replace NaNs with 0)\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_val = np.nan_to_num(X_val)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', probability=True, C=1.0, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(C=1.0, max_iter=1000, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_predictions = {}\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"-----------------\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model on years 1-9\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Training accuracy\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred) * 100\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Validate on year 10\n",
    "    y_val_pred = model.predict(X_val_scaled)\n",
    "\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Training F1 Score: {train_f1:.2f}\")\n",
    "    print(f\"Training Precision: {train_precision:.2f}\")\n",
    "    print(f\"Training Recall: {train_recall:.2f}\")\n",
    "    \n",
    "    # Make predictions for year 11\n",
    "    X_predict = []\n",
    "    for _, team in teams_year_11.iterrows():\n",
    "        features = create_features_for_team(team, teams_10_years, players_teams_10_years, coaches__10_years, 10)  # Utilizamos o 10º ano para criar as features\n",
    "        X_predict.append(features)\n",
    "\n",
    "    # Scale the features\n",
    "    X_predict_scaled = scaler.transform(np.array(X_predict))\n",
    "    \n",
    "    # Get binary predictions (0 or 1)\n",
    "    playoff_predictions = model.predict(X_predict_scaled)  # This gives the final predicted values (not probabilities)\n",
    "    \n",
    "    # Create DataFrame with predictions (removed probabilities)\n",
    "    pred_df = pd.DataFrame({\n",
    "        'tmID': teams_year_11['tmID'],\n",
    "        'confID': teams_year_11['confID'],\n",
    "        'playoff_pred': playoff_predictions  # Only store the predicted values\n",
    "    })\n",
    "    \n",
    "    # Select top 4 teams from each conference based on predictions\n",
    "    predictions = []\n",
    "    for conf in [0, 1]:  # Eastern and Western conferences\n",
    "        conf_teams = pred_df[pred_df['confID'] == conf].nlargest(4, 'playoff_pred')\n",
    "        predictions.extend(conf_teams['tmID'].tolist())\n",
    "    \n",
    "    # Create a final list of predictions with 0 for teams not in the top 4\n",
    "    all_teams_predictions = {team_id: 0 for team_id in teams_year_11['tmID']}  # Default to 0 (not in playoffs)\n",
    "    \n",
    "    # Mark the top 4 teams in each conference as 1 (in playoffs)\n",
    "    for team_id in predictions:\n",
    "        all_teams_predictions[team_id] = 1\n",
    "    \n",
    "    # Print all teams' predictions\n",
    "    print(\"\\nTeam Playoff Predictions for Year 11:\")\n",
    "    for team_id, prediction in all_teams_predictions.items():\n",
    "        print(f\"Team {team_id}: Predicted = {prediction}\")\n",
    "    \n",
    "    # Store predictions and metrics (removed probabilities)\n",
    "    model_predictions[name] = {\n",
    "        'training_accuracy': train_accuracy,\n",
    "        'training_f1': train_f1,\n",
    "        'training_precision': train_precision,\n",
    "        'training_recall': train_recall,\n",
    "        'predictions': all_teams_predictions,  # Store 0 or 1 for all teams\n",
    "    }\n",
    "\n",
    "# Identify best model based on training accuracy\n",
    "best_model = max(model_predictions.items(), key=lambda x: x[1]['training_accuracy'])\n",
    "print(f\"\\nBest Model: {best_model[0]}\")\n",
    "print(f\"Training Accuracy: {best_model[1]['training_accuracy']:.2f}%\")\n",
    "\n",
    "# Save results and feature importance for Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "feature_names = ['won', 'lost', 'o_pts', 'd_pts', 'o_reb', 'd_reb', 'confID', \n",
    "                'win_rate_3yr', 'playoff_rate_3yr', 'points_diff_3yr',\n",
    "                'player_overall_avg', 'player_stamina_avg', 'player_defense_avg', \n",
    "                'player_offense_avg', 'coach_overall', 'is_new_team']\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'model_predictions': model_predictions,\n",
    "    'best_model': {\n",
    "        'name': best_model[0],\n",
    "        'training_accuracy': best_model[1]['training_accuracy'],\n",
    "        'predictions': best_model[1]['predictions']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the predictions and metrics\n",
    "pd.DataFrame([results]).to_csv('../data/Season_11/ml_model_results.csv', index=False)\n",
    "\n",
    "# Save the predictions in a CSV file for further analysis\n",
    "predictions_df = pd.DataFrame({\n",
    "    'model': [best_model[0]] * len(best_model[1]['predictions']),\n",
    "    'team_id': list(best_model[1]['predictions'].keys()),\n",
    "    'predicted_playoffs': list(best_model[1]['predictions'].values())\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('../data/Season_11/team_playoff_predictions.csv', index=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance in Playoff Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
